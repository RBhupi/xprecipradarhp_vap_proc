{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00645963",
   "metadata": {},
   "source": [
    "# HP Processing Pipeline - DOD Template Based\n",
    "\n",
    "Process radar files and output to DOD-compliant NetCDF using template header structure.\n",
    "\n",
    "**Workflow:**\n",
    "0. Make netcdf from DOD\n",
    "1. Provide DOD template NetCDF file path\n",
    "2. Provide radar input file path  \n",
    "3. Process radar data (classify, grid)\n",
    "4. Write output using DOD template header with processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1482bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import act\n",
    "\n",
    "# Add path to access hp_processing functions\n",
    "sys.path.insert(0, '/Users/bhupendra/projects/sail/Python')\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1afb10",
   "metadata": {},
   "source": [
    "## 0. Create NetCDF From DOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bf878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DOD dataset: xprecipradarhp.c1 c1 v1.3\n",
      "Dimensions: {'time': 1, 'y': 160, 'x': 160, 'bound': 2}\n",
      "✓ DOD dataset created successfully\n",
      "  Dimensions: {'time': 1, 'y': 160, 'x': 160}\n",
      "  Variables: ['base_time', 'time_offset', 'corrected_reflectivity', 'hp_fhc', 'hp_ssc', 'lowest_height', 'lat', 'lon', 'radar_lat', 'radar_lon', 'radar_alt']\n",
      "  Coordinates: ['time', 'y', 'x']\n",
      "✓ DOD dataset created successfully\n",
      "  Dimensions: {'time': 1, 'y': 160, 'x': 160}\n",
      "  Variables: ['base_time', 'time_offset', 'corrected_reflectivity', 'hp_fhc', 'hp_ssc', 'lowest_height', 'lat', 'lon', 'radar_lat', 'radar_lon', 'radar_alt']\n",
      "  Coordinates: ['time', 'y', 'x']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/hb5cyy892hqdjht868lw3qk80000gp/T/ipykernel_10026/555310920.py:29: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"  Dimensions: {dict(dod_ds.dims)}\")\n"
     ]
    }
   ],
   "source": [
    "# Define DOD parameters for xprecipradarhp-c1-1.3\n",
    "proc = 'xprecipradarhp.c1'\n",
    "version = '1.3'\n",
    "\n",
    "# Set dimensions as per DOD spec\n",
    "set_dims = {\n",
    "    'time': 1,  # UNLIMITED, but we process one time slice\n",
    "    'y': 160,\n",
    "    'x': 160,\n",
    "    'bound': 2\n",
    "}\n",
    "\n",
    "DOD_FILL_VALUE = -9999.0\n",
    "scalar_fill_dim = 'time'  # For scalar variables with time dimension\n",
    "\n",
    "print(f\"Creating DOD dataset: {proc} {level} v{version}\")\n",
    "print(f\"Dimensions: {set_dims}\")\n",
    "\n",
    "dod_ds = act.io.create_ds_from_arm_dod(\n",
    "    proc, \n",
    "    set_dims, \n",
    "    version=version,\n",
    "    fill_value=DOD_FILL_VALUE,\n",
    "    scalar_fill_dim=scalar_fill_dim,\n",
    "    local_file=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20416efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DOD template saved: /Users/bhupendra/projects/sail/vaps/hp_proc/dod_template.nc\n",
      "  File size: 68.0 KB\n",
      "  Variables: ['base_time', 'time_offset', 'corrected_reflectivity', 'hp_fhc', 'hp_ssc', 'lowest_height', 'lat', 'lon', 'radar_lat', 'radar_lon', 'radar_alt']\n",
      "  Dimensions: {'time': 1, 'y': 160, 'x': 160}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/hb5cyy892hqdjht868lw3qk80000gp/T/ipykernel_10026/3442009200.py:17: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(f\"  Dimensions: {dict(dod_ds.dims)}\")\n"
     ]
    }
   ],
   "source": [
    "# Save DOD template to compressed NetCDF4 file\n",
    "dod_file_path = '/Users/bhupendra/projects/sail/vaps/hp_proc/dod_template.nc'\n",
    "\n",
    "# Convert xarray to NetCDF4 format with compression\n",
    "encoding = {}\n",
    "for var in dod_ds.data_vars:\n",
    "    encoding[var] = {\n",
    "        'zlib': True,\n",
    "        'complevel': 4,\n",
    "        'dtype': dod_ds[var].dtype\n",
    "    }\n",
    "\n",
    "dod_ds.to_netcdf(dod_file_path, encoding=encoding, format='NETCDF4')\n",
    "print(f\"✓ DOD template saved: {dod_file_path}\")\n",
    "print(f\"  File size: {Path(dod_file_path).stat().st_size / 1024:.1f} KB\")\n",
    "print(f\"  Variables: {list(dod_ds.data_vars.keys())}\")\n",
    "print(f\"  Dimensions: {dict(dod_ds.dims)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefea0e1",
   "metadata": {},
   "source": [
    "## 1. Define Function to Read NetCDF Header\n",
    "\n",
    "Extract structure (dimensions, variables, attributes) from DOD template file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c697404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_netcdf_header(dod_file_path):\n",
    "    \"\"\"\n",
    "    Extract header information from DOD template NetCDF file.\n",
    "    \n",
    "    Returns dict with:\n",
    "    - dimensions: {name: size}\n",
    "    - variables: {name: (dims, dtype, attributes)}\n",
    "    - global_attrs: {name: value}\n",
    "    \"\"\"\n",
    "    with netCDF4.Dataset(dod_file_path, 'r') as ds:\n",
    "        header = {\n",
    "            'dimensions': dict(ds.dimensions),\n",
    "            'variables': {},\n",
    "            'global_attrs': {k: ds.getncattr(k) for k in ds.ncattrs()}\n",
    "        }\n",
    "        \n",
    "        for var_name in ds.variables:\n",
    "            var = ds.variables[var_name]\n",
    "            header['variables'][var_name] = {\n",
    "                'dims': var.dimensions,\n",
    "                'dtype': var.dtype,\n",
    "                'shape': var.shape,\n",
    "                'attrs': {k: var.getncattr(k) for k in var.ncattrs()}\n",
    "            }\n",
    "    \n",
    "    return header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58bb6a",
   "metadata": {},
   "source": [
    "## 2. Define Function to Create Output NetCDF with Header\n",
    "\n",
    "Create output file with same structure as DOD template (empty, ready for data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "611a7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_netcdf(output_path, header):\n",
    "    \"\"\"\n",
    "    Create output NetCDF file with DOD template structure.\n",
    "    Returns open Dataset for writing data.\n",
    "    \"\"\"\n",
    "    ds = netCDF4.Dataset(output_path, 'w', format='NETCDF4')\n",
    "    \n",
    "    # Create dimensions\n",
    "    for dim_name, dim_size in header['dimensions'].items():\n",
    "        ds.createDimension(dim_name, dim_size)\n",
    "    \n",
    "    # Create variables with attributes\n",
    "    for var_name, var_info in header['variables'].items():\n",
    "        var = ds.createVariable(\n",
    "            var_name,\n",
    "            var_info['dtype'],\n",
    "            dimensions=var_info['dims'],\n",
    "            fill_value=var_info['attrs'].get('_FillValue', None)\n",
    "        )\n",
    "        \n",
    "        # Add attributes\n",
    "        for attr_name, attr_value in var_info['attrs'].items():\n",
    "            if attr_name != '_FillValue':\n",
    "                try:\n",
    "                    var.setncattr(attr_name, attr_value)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not set {attr_name} for {var_name}: {e}\")\n",
    "    \n",
    "    # Add global attributes\n",
    "    for attr_name, attr_value in header['global_attrs'].items():\n",
    "        try:\n",
    "            ds.setncattr(attr_name, attr_value)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not set global attribute {attr_name}: {e}\")\n",
    "    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f664f3",
   "metadata": {},
   "source": [
    "## 3. Define Function to Read and Process Radar File\n",
    "\n",
    "Process radar data using existing hp_processing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59123eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_radar_file(radar_file, season='summer'):\n",
    "    \"\"\"\n",
    "    Process radar file and return processed data dict with:\n",
    "    - corrected_reflectivity: (time, y, x)\n",
    "    - hp_fhc: (time, y, x)\n",
    "    - hp_ssc: (time, y, x)\n",
    "    - lowest_height: (time, y, x)\n",
    "    - lat: (y, x)\n",
    "    - lon: (y, x)\n",
    "    - radar_lat, radar_lon, radar_alt: scalars\n",
    "    \"\"\"\n",
    "    from hp_processing import process_radar, make_squire_grid\n",
    "    \n",
    "    print(f\"Reading {radar_file}...\")\n",
    "    radar = process_radar(radar_file, season)\n",
    "    \n",
    "    print(\"Gridding and extracting data...\")\n",
    "    data_ds = make_squire_grid(radar)\n",
    "    \n",
    "    # Extract lowest vertical level\n",
    "    dbz = data_ds['corrected_reflectivity'].values[0, :, :]  # (y, x)\n",
    "    hp_fhc = data_ds['hp_fhc'].values[0, :, :] if 'hp_fhc' in data_ds else np.full((160, 160), -9999, dtype=np.int16)\n",
    "    hp_ssc = data_ds['hp_ssc'].values[0, :, :] if 'hp_ssc' in data_ds else np.full((160, 160), -9999, dtype=np.int16)\n",
    "    lowest_h = data_ds['lowest_height'].values[0, :, :] if 'lowest_height' in data_ds else np.full((160, 160), -9999)\n",
    "    lat = data_ds['lat'].values  # (y, x)\n",
    "    lon = data_ds['lon'].values  # (y, x)\n",
    "    \n",
    "    # Expand to time dimension (1, y, x)\n",
    "    dbz = np.expand_dims(dbz, axis=0)\n",
    "    hp_fhc = np.expand_dims(hp_fhc, axis=0)\n",
    "    hp_ssc = np.expand_dims(hp_ssc, axis=0)\n",
    "    lowest_h = np.expand_dims(lowest_h, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'corrected_reflectivity': dbz,\n",
    "        'hp_fhc': hp_fhc,\n",
    "        'hp_ssc': hp_ssc,\n",
    "        'lowest_height': lowest_h,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'radar_lat': float(data_ds.attrs.get('radar_latitude', -9999)),\n",
    "        'radar_lon': float(data_ds.attrs.get('radar_longitude', -9999)),\n",
    "        'radar_alt': float(data_ds.attrs.get('radar_altitude', -9999)),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be0c757",
   "metadata": {},
   "source": [
    "## 4. Define Function to Write Processed Data to Output\n",
    "\n",
    "Populate output NetCDF with processed radar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a6d7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_to_netcdf(ds, processed_data):\n",
    "    \"\"\"\n",
    "    Write processed radar data to NetCDF Dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Write main data variables\n",
    "        if 'corrected_reflectivity' in ds.variables:\n",
    "            ds.variables['corrected_reflectivity'][:] = processed_data['corrected_reflectivity']\n",
    "        \n",
    "        if 'hp_fhc' in ds.variables:\n",
    "            ds.variables['hp_fhc'][:] = processed_data['hp_fhc'].astype(ds.variables['hp_fhc'].dtype)\n",
    "        \n",
    "        if 'hp_ssc' in ds.variables:\n",
    "            ds.variables['hp_ssc'][:] = processed_data['hp_ssc'].astype(ds.variables['hp_ssc'].dtype)\n",
    "        \n",
    "        if 'lowest_height' in ds.variables:\n",
    "            ds.variables['lowest_height'][:] = processed_data['lowest_height']\n",
    "        \n",
    "        # Write coordinate variables\n",
    "        if 'lat' in ds.variables:\n",
    "            ds.variables['lat'][:] = processed_data['lat']\n",
    "        \n",
    "        if 'lon' in ds.variables:\n",
    "            ds.variables['lon'][:] = processed_data['lon']\n",
    "        \n",
    "        # Write scalar radar location variables\n",
    "        if 'radar_lat' in ds.variables:\n",
    "            ds.variables['radar_lat'][0] = processed_data['radar_lat']\n",
    "        \n",
    "        if 'radar_lon' in ds.variables:\n",
    "            ds.variables['radar_lon'][0] = processed_data['radar_lon']\n",
    "        \n",
    "        if 'radar_alt' in ds.variables:\n",
    "            ds.variables['radar_alt'][0] = processed_data['radar_alt']\n",
    "        \n",
    "        print(\"Data written successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing data: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741764f",
   "metadata": {},
   "source": [
    "## 5. MAIN EXECUTION - Provide Your File Paths Here\n",
    "\n",
    "Edit these three variables with your actual file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THESE THREE VARIABLES\n",
    "dod_template_file = \"/Users/bhupendra/projects/sail/vaps/hp_proc/dod_template.nc\"  # DOD template NetCDF file\n",
    "radar_input_file = \"/\"     # Radar input file\n",
    "output_file = \"/path/to/output.nc\"              # Output file path\n",
    "season = \"summer\"                                # \"summer\" or \"winter\"\n",
    "\n",
    "print(f\"DOD Template: {dod_template_file}\")\n",
    "print(f\"Radar Input: {radar_input_file}\")\n",
    "print(f\"Output File: {output_file}\")\n",
    "print(f\"Season: {season}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5d2c6",
   "metadata": {},
   "source": [
    "### Step 1: Read DOD Template Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd715a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = read_netcdf_header(dod_template_file)\n",
    "print(f\"✓ Header loaded from {Path(dod_template_file).name}\")\n",
    "print(f\"  Dimensions: {dict(header['dimensions'])}\")\n",
    "print(f\"  Variables: {list(header['variables'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723a3ef",
   "metadata": {},
   "source": [
    "### Step 2: Process Radar File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b086ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process_radar_file(radar_input_file, season)\n",
    "print(f\"✓ Radar processing complete\")\n",
    "print(f\"  corrected_reflectivity shape: {processed_data['corrected_reflectivity'].shape}\")\n",
    "print(f\"  hp_fhc shape: {processed_data['hp_fhc'].shape}\")\n",
    "print(f\"  hp_ssc shape: {processed_data['hp_ssc'].shape}\")\n",
    "print(f\"  lowest_height shape: {processed_data['lowest_height'].shape}\")\n",
    "print(f\"  lat shape: {processed_data['lat'].shape}\")\n",
    "print(f\"  radar location: ({processed_data['radar_lat']}, {processed_data['radar_lon']}, {processed_data['radar_alt']}m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8580cd4d",
   "metadata": {},
   "source": [
    "### Step 3: Create Output NetCDF with DOD Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ds = create_output_netcdf(output_file, header)\n",
    "print(f\"✓ Output NetCDF created: {output_file}\")\n",
    "print(f\"  Dimensions: {dict(output_ds.dimensions)}\")\n",
    "print(f\"  Variables: {list(output_ds.variables.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350deb3",
   "metadata": {},
   "source": [
    "### Step 4: Write Processed Data to Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data_to_netcdf(output_ds, processed_data)\n",
    "output_ds.close()\n",
    "print(f\"✓ Output file closed: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968aec6",
   "metadata": {},
   "source": [
    "## 6. Verify Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81386db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OUTPUT FILE VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with netCDF4.Dataset(output_file, 'r') as verify_ds:\n",
    "    print(f\"\\nFile: {output_file}\")\n",
    "    print(f\"\\nDimensions:\")\n",
    "    for dim_name, dim_size in verify_ds.dimensions.items():\n",
    "        print(f\"  {dim_name}: {dim_size}\")\n",
    "    \n",
    "    print(f\"\\nVariables and shapes:\")\n",
    "    for var_name in verify_ds.variables:\n",
    "        var = verify_ds.variables[var_name]\n",
    "        print(f\"  {var_name}: {var.shape} ({var.dtype})\")\n",
    "    \n",
    "    print(f\"\\nGlobal attributes ({len(verify_ds.ncattrs())}):\")\n",
    "    for attr in list(verify_ds.ncattrs())[:5]:  # Show first 5\n",
    "        print(f\"  {attr}\")\n",
    "    \n",
    "    print(\"\\n✓ Output file structure verified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
